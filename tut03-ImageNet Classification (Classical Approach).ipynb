{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLVC 2017\n",
    "# 2nd July 2017, Tutorial 2\n",
    "# ImageNet Classification (Classical Approach)\n",
    "\n",
    "#### Dataset: Tiny ImageNet [https://tiny-imagenet.herokuapp.com/]\n",
    "Tiny Imagenet has 200 classes. Each class has 500 training images, 50 validation images, and 50 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import pickle\n",
    "from skimage import feature\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "\n",
    "if not os.path.exists('tut03-results'):\n",
    "    os.makedirs('tut03-results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_immediate_subdirectories(a_dir):\n",
    "    return [name for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]\n",
    "def get_imlist(path):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if f.endswith('.JPEG')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile('data/tut03/tiny-imagenet-200.zip', 'r')\n",
    "zip_ref.extractall('data/tut03/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datasetPath = 'data/tut03/tiny-imagenet-200/train';\n",
    "classes = get_immediate_subdirectories(train_datasetPath)\n",
    "train_img_list = [get_imlist(os.path.join(train_datasetPath,classes[num]+'/images/')) for num in range(len(classes))]\n",
    "test_datasetPath = 'data/tut03/tiny-imagenet-200/val';\n",
    "test_img_list = get_imlist(test_datasetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_greycoHomFeat = []\n",
    "train_greycoConFeat = []\n",
    "train_greycoEnFeat = []\n",
    "train_greycoCorrFeat = []\n",
    "train_hogFeat = []\n",
    "train_lbpFeat = []\n",
    "for num1 in range(200):\n",
    "    for num2 in range(len(train_img_list[num1])):\n",
    "        img = Image.open(train_img_list[num1][num2])\n",
    "        train_greycoHomFeat.append(feature.greycoprops(feature.greycomatrix(array(img.convert('L')), [1], [np.pi/4],normed=True),prop='homogeneity'))\n",
    "        train_greycoConFeat.append(feature.greycoprops(feature.greycomatrix(array(img.convert('L')), [1], [np.pi/4],normed=True),prop='contrast'))\n",
    "        train_greycoEnFeat.append(feature.greycoprops(feature.greycomatrix(array(img.convert('L')), [1], [np.pi/4],normed=True),prop='energy'))\n",
    "        train_greycoCorrFeat.append(feature.greycoprops(feature.greycomatrix(array(img.convert('L')), [1], [np.pi/4],normed=True),prop='correlation'))\n",
    "        train_hogFeat.append(feature.hog(array(img.convert('L')), orientations=4, pixels_per_cell=(15,15))) \n",
    "        train_lbpFeat.append(feature.local_binary_pattern(array(img.convert('L')), 5, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('tut03-result/train_greycoHomFeat.pkl','wb') as f:\n",
    "    pickle.dump(train_greycoHomFeat,f)\n",
    "with open('tut03-results/train_greycoConFeat.pkl','wb') as f:\n",
    "    pickle.dump(train_greycoHomFeat,f)\n",
    "with open('tut03-results/train_greycoEnFeat.pkl','wb') as f:\n",
    "    pickle.dump(train_greycoEnFeat,f)\n",
    "with open('tut03-results/train_greycoCorrFeat.pkl','wb') as f:\n",
    "    pickle.dump(train_greycoCorrFeat,f)\n",
    "with open('tut03-results/train_hogFeat.pkl','wb') as f:\n",
    "    pickle.dump(train_hogFeat,f)\n",
    "with open('tut03-results/train_lbpFeat.pkl','wb') as f:\n",
    "    pickle.dump(train_lbpFeat,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_greycoHomFeat = []\n",
    "test_greycoConFeat = []\n",
    "test_greycoEnFeat = []\n",
    "test_greycoCorrFeat = []\n",
    "test_hogFeat = []\n",
    "test_lbpFeat = []\n",
    "\n",
    "for num1 in range(len(test_img_list)):\n",
    "    img = Image.open(test_img_list[num1])\n",
    "    train_greycoHomFeat.append(feature.greycoprops(feature.greycomatrix(array(img.convert('L')), [1], [np.pi/4],normed=True),prop='homogeneity'))\n",
    "    train_greycoConFeat.append(feature.greycoprops(feature.greycomatrix(array(img.convert('L')), [1], [np.pi/4],normed=True),prop='contrast'))\n",
    "    train_greycoEnFeat.append(feature.greycoprops(feature.greycomatrix(array(img.convert('L')), [1], [np.pi/4],normed=True),prop='energy')\n",
    "    train_greycoCorrFeat.append(feature.greycoprops(feature.greycomatrix(array(img.convert('L')), [1], [np.pi/4],normed=True),prop='correlation')                          \n",
    "    train_hogFeat.append(feature.hog(array(img.convert('L')), orientations=4, pixels_per_cell=(15,15)) \n",
    "    train_lbpFeat.append(feature.local_binary_pattern(array(img.convert('L')), 5, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tut03-results/test_greycoHomFeat.pkl','wb') as f:\n",
    "    pickle.dump(test_greycoHomFeat,f)\n",
    "with open('tut03-results/test_greycoConFeat.pkl','wb') as f:\n",
    "    pickle.dump(test_greycoConFeat,f)\n",
    "with open('tut03-results/test_greycoEnFeat.pkl','wb') as f:\n",
    "    pickle.dump(test_greycoEnFeat,f)\n",
    "with open('tut03-results/test_greycoCorrFeat.pkl','wb') as f:\n",
    "    pickle.dump(test_greycoCorrFeat,f)\n",
    "with open('tut03-results/test_hogFeat.pkl','wb') as f:\n",
    "    pickle.dump(test_hogFeat,f)\n",
    "with open('tut03-results/test_lbpFeat.pkl','wb') as f:\n",
    "    pickle.dump(test_lbpFeat,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_lbpFeat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-38b82dd71100>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Training and testing labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_lbpFeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_lbpFeat' is not defined"
     ]
    }
   ],
   "source": [
    "## Training and testing labels\n",
    "train_label = np.zeros(len(test_lbpFeat))\n",
    "t = 0\n",
    "for num1 in range(200):\n",
    "    L = len(train_img_list[num1])\n",
    "    train_label[t:t+L-1] = num1\n",
    "    t = t+L\n",
    "    \n",
    "test_label = np.zeros(len(test_list))\n",
    "lines = []\n",
    "with open(os.path.join(test_datasetPath,'val_annotations.txt'),'r') as f:\n",
    "    for line in f:\n",
    "        lines.append(line.split())       \n",
    "test_list = [x[1] for x in lines]\n",
    "for num2 in range(len(test_list)):\n",
    "    test_label[num2]= classes.index(test_list[num2])   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample concatenation to find feature length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "trainFeat = np.zeros((60000,1896))\n",
    "for num in range(60000):    \n",
    "    trainFeat[num][:] = np.concatenate((train_greycoHomFeat[num].reshape(1,),train_greycoConFeat[num].reshape(1,),\n",
    "                            train_greycoEnFeat[num].reshape(1,),train_greycoCorrFeat[num].reshape(1,),\n",
    "                                        train_hogFeat[num],train_lbpFeat[num].reshape(28*28),train_data[num].reshape(28*28)),axis=0)\n",
    "\n",
    "testFeat = np.zeros((10000,1896))\n",
    "for num in range(10000):    \n",
    "    trainFeat[num][:] = np.concatenate((test_greycoHomFeat[num].reshape(1,),test_greycoConFeat[num].reshape(1,),\n",
    "                            test_greycoEnFeat[num].reshape(1,),test_greycoCorrFeat[num].reshape(1,),\n",
    "                                        test_hogFeat[num],test_lbpFeat[num].reshape(28*28),test_data[num].reshape(28*28)),axis=0)\n",
    "trainFeat_scaled = preprocessing.scale(trainFeat)\n",
    "testFeat_scaled = preprocessing.scale(testFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#scikitlearn documentation for MLP classifier: goo.gl/F1Q1Fa\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=1e-4,\n",
    "                    solver='sgd', verbose=True, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=1e-2)\n",
    "nn.fit(trainFeat_scaled, train_label)       \n",
    "prediction = nn.predict(testFeat_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Training set score: %f\" % nn.score(trainFeat_scaled, train_label)) # mean accuracy\n",
    "print(\"Test set score: %f\" % nn.score(testFeat_scaled, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
